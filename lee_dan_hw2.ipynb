{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dan Lee\n",
    "# CMSC 491 Computer Vision\n",
    "# Assignment #2\n",
    "# Due Date: 4/14/19\n",
    "# Late Submission on 4/15/19 - which leaves me 3 more passes for the semester\n",
    "\n",
    "import numpy as np # basic array manipulation\n",
    "import scipy as sc # submodule dedicated to image processing (n-dimensional images) \n",
    "from PIL import Image # for reading images and converting images from numpy arrays\n",
    "from matplotlib import pyplot as plt # for rendering the images \n",
    "import math # for basic math functions that do not manipulate arrays\n",
    "import imageio # for a more convenient way writing images to files (PLEASE REFER TO PDF )\n",
    "import cv2 # like TA said, ONLY used for the smaller functions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# REMINDER TO SELF BEFORE SUBMITTING: 'Kernel > Restart' (restart the kernel) and then 'Cell > Run All' (run the script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS A PART OF FILE THAT THE TA GAVE TO US\n",
    "# may or may not use, because of bugs\n",
    "\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import rank_filter\n",
    "from scipy.ndimage import filters\n",
    "from scipy.stats import norm\n",
    "\n",
    "def gen_dgauss(sigma):\n",
    "    \"\"\"\n",
    "    Generates the horizontally and vertically differentiated Gaussian filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: float\n",
    "        Standard deviation of the Gaussian distribution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gx: numpy.ndarray\n",
    "        First degree derivative of the Gaussian filter across rows\n",
    "    Gy: numpy.ndarray\n",
    "        First degree derivative of the Gaussian filter across columns\n",
    "    \"\"\"\n",
    "    f_wid = 4 * np.floor(sigma)\n",
    "    G = norm.pdf(np.arange(-f_wid, f_wid + 1),\n",
    "                 loc=0, scale=sigma).reshape(-1, 1)\n",
    "    G = G.T * G\n",
    "    Gx, Gy = np.gradient(G)\n",
    "\n",
    "    Gx = Gx * 2 / np.abs(Gx).sum()\n",
    "    Gy = Gy * 2 / np.abs(Gy).sum()\n",
    "\n",
    "    return Gx, Gy\n",
    "\n",
    "\n",
    "def find_sift(I, circles, enlarge_factor=1.5):\n",
    "    \"\"\"\n",
    "    Compute non-rotation-invariant SITF descriptors of a set of circles\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    I: numpy.ndarray\n",
    "        Image\n",
    "    circles: numpy.ndarray\n",
    "        An array of shape `(ncircles, 3)` where ncircles is the number of\n",
    "        circles, and each circle is defined by (x, y, r), where r is the radius\n",
    "        of the cirlce\n",
    "    enlarge_factor: float\n",
    "        Factor which indicates by how much to enlarge the radius of the circle\n",
    "        before computing the descriptor (a factor of 1.5 or large is usually\n",
    "        necessary for best performance)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sift_arr: numpy.ndarray\n",
    "        Array of SIFT descriptors of shape `(ncircles, 128)`\n",
    "    \"\"\"\n",
    "    assert circles.ndim == 2 and circles.shape[1] == 3, \\\n",
    "        'Use circles array (keypoints array) of correct shape'\n",
    "    I = I.astype(np.float64)\n",
    "    if I.ndim == 3:\n",
    "        I = rgb2gray(I)\n",
    "\n",
    "    NUM_ANGLES = 8\n",
    "    NUM_BINS = 4\n",
    "    NUM_SAMPLES = NUM_BINS * NUM_BINS\n",
    "    ALPHA = 9\n",
    "    SIGMA_EDGE = 1\n",
    "\n",
    "    ANGLE_STEP = 2 * np.pi / NUM_ANGLES\n",
    "    angles = np.arange(0, 2 * np.pi, ANGLE_STEP)\n",
    "\n",
    "    height, width = I.shape[:2]\n",
    "    num_pts = circles.shape[0]\n",
    "\n",
    "    sift_arr = np.zeros((num_pts, NUM_SAMPLES * NUM_ANGLES))\n",
    "\n",
    "    Gx, Gy = gen_dgauss(SIGMA_EDGE)\n",
    "\n",
    "    Ix = convolve2d(I, Gx, 'same')\n",
    "    Iy = convolve2d(I, Gy, 'same')\n",
    "    I_mag = np.sqrt(Ix ** 2 + Iy ** 2)\n",
    "    I_theta = np.arctan2(Ix, Iy + 1e-12)\n",
    "\n",
    "    interval = np.arange(-1 + 1/NUM_BINS, 1 + 1/NUM_BINS, 2/NUM_BINS)\n",
    "    gridx, gridy = np.meshgrid(interval, interval)\n",
    "    gridx = gridx.reshape((1, -1))\n",
    "    gridy = gridy.reshape((1, -1))\n",
    "\n",
    "    I_orientation = np.zeros((height, width, NUM_ANGLES))\n",
    "\n",
    "    for i in range(NUM_ANGLES):\n",
    "        tmp = np.cos(I_theta - angles[i]) ** ALPHA\n",
    "        tmp = tmp * (tmp > 0)\n",
    "\n",
    "        I_orientation[:, :, i] = tmp * I_mag\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        cx, cy = circles[i, :2]\n",
    "        r = circles[i, 2]\n",
    "\n",
    "        gridx_t = gridx * r + cx\n",
    "        gridy_t = gridy * r + cy\n",
    "        grid_res = 2.0 / NUM_BINS * r\n",
    "\n",
    "        x_lo = np.floor(np.max([cx - r - grid_res / 2, 0])).astype(np.int32)\n",
    "        x_hi = np.ceil(np.min([cx + r + grid_res / 2, width])).astype(np.int32)\n",
    "        y_lo = np.floor(np.max([cy - r - grid_res / 2, 0])).astype(np.int32)\n",
    "        y_hi = np.ceil(\n",
    "            np.min([cy + r + grid_res / 2, height])).astype(np.int32)\n",
    "\n",
    "        grid_px, grid_py = np.meshgrid(\n",
    "            np.arange(x_lo, x_hi, 1),\n",
    "            np.arange(y_lo, y_hi, 1))\n",
    "        grid_px = grid_px.reshape((-1, 1))\n",
    "        grid_py = grid_py.reshape((-1, 1))\n",
    "\n",
    "        dist_px = np.abs(grid_px - gridx_t)\n",
    "        dist_py = np.abs(grid_py - gridy_t)\n",
    "\n",
    "        weight_x = dist_px / (grid_res + 1e-12)\n",
    "        weight_x = (1 - weight_x) * (weight_x <= 1)\n",
    "        weight_y = dist_py / (grid_res + 1e-12)\n",
    "        weight_y = (1 - weight_y) * (weight_y <= 1)\n",
    "        weights = weight_x * weight_y\n",
    "\n",
    "        curr_sift = np.zeros((NUM_ANGLES, NUM_SAMPLES))\n",
    "        for j in range(NUM_ANGLES):\n",
    "            tmp = I_orientation[y_lo:y_hi, x_lo:x_hi, j].reshape((-1, 1))\n",
    "            curr_sift[j, :] = (tmp * weights).sum(axis=0)\n",
    "        sift_arr[i, :] = curr_sift.flatten()\n",
    "\n",
    "    tmp = np.sqrt(np.sum(sift_arr ** 2, axis=-1))\n",
    "    if np.sum(tmp > 1) > 0:\n",
    "        sift_arr_norm = sift_arr[tmp > 1, :]\n",
    "        sift_arr_norm /= tmp[tmp > 1].reshape(-1, 1)\n",
    "\n",
    "        sift_arr_norm = np.clip(sift_arr_norm, sift_arr_norm.min(), 0.2)\n",
    "\n",
    "        sift_arr_norm /= np.sqrt(\n",
    "            np.sum(sift_arr_norm ** 2, axis=-1, keepdims=True))\n",
    "\n",
    "        sift_arr[tmp > 1, :] = sift_arr_norm\n",
    "\n",
    "    return sift_arr\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Gx, Gy = gen_dgauss(3.2)\n",
    "    print(f'Gx.shape: {Gx.shape}')\n",
    "    I = np.random.random((480, 640, 3)) * 255\n",
    "    circles = np.vstack([\n",
    "        np.random.randint(1, 480, 25),\n",
    "        np.random.randint(1, 640, 25),\n",
    "        15 * np.random.random(25)]).T\n",
    "\n",
    "    sift_arr = find_sift(I, circles)\n",
    "    print(sift_arr.shape)\n",
    "\n",
    "#     cim, r, c = harris(I, 3.2, thresh=5, radius=3)\n",
    "\n",
    "#     print(f'cim.shape: {cim.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Load both images - convert to grayscale and double\n",
    "imgLeft = np.float32(np.array(Image.open('uttower_left.JPG').convert(\"L\")))\n",
    "imgRight = np.float32(np.array(Image.open('uttower_right.JPG').convert(\"L\"))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Detect feature points in both images with harris corner detection function.\n",
    "# cimL, rL, cL = harris(grayL, 2, 0.05, 2)\n",
    "# create coordinates from rL and cL - a total of 4898 coordinates exist\n",
    "# filtered_coordsL = np.stack((rL, cL), axis=-1)\n",
    "# convert from ndarray to list for computation on coordinates\n",
    "# filtered_coordsL.tolist()\n",
    "# print(len(filtered_coordsL))\n",
    "\n",
    "# Due to issues with matching b/w coords extracted from the harris function in util\n",
    "# provided by the TA I am using another harris detection function - using another harris implementation found on the web\n",
    "\n",
    "def harris(im,min_dist=10,threshold=0.1):\n",
    "    # derivatives\n",
    "    imx = np.zeros(im.shape)\n",
    "    filters.gaussian_filter(im, (3,3), (0,1), imx)\n",
    "    imy = np.zeros(im.shape)\n",
    "    filters.gaussian_filter(im, (3,3), (1,0), imy)\n",
    "    # compute components of the Harris matrix\n",
    "    Wxx = filters.gaussian_filter(imx*imx,3)\n",
    "    Wxy = filters.gaussian_filter(imx*imy,3)\n",
    "    Wyy = filters.gaussian_filter(imy*imy,3)\n",
    "    # determinant and trace\n",
    "    Wdet = Wxx*Wyy - Wxy**2\n",
    "    Wtr = Wxx + Wyy\n",
    "    harrisim = (Wdet / Wtr)\n",
    "    # find top corner candidates above a threshold\n",
    "    corner_threshold = harrisim.max() * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1\n",
    "    # get coordinates of candidates\n",
    "    coords = np.array(harrisim_t.nonzero()).T\n",
    "    # ...and their values\n",
    "    candidate_values = [harrisim[c[0],c[1]] for c in coords]\n",
    "    # sort candidates\n",
    "    index = np.argsort(candidate_values)\n",
    "    # store allowed point locations in array\n",
    "    allowed_locations = np.zeros(harrisim.shape)\n",
    "    allowed_locations[min_dist:-min_dist,min_dist:-min_dist] = 1\n",
    "    # select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i,0],coords[i,1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i,0]-min_dist):(coords[i,0]+min_dist),\n",
    "            (coords[i,1]-min_dist):(coords[i,1]+min_dist)] = 0\n",
    "    return filtered_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_coordsL = harris(imgLeft,6)\n",
    "print(len(filtered_coordsL))\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(imgLeft)\n",
    "plt.plot([p[1] for p in filtered_coordsL],[p[0] for p in filtered_coordsL],\"*\")\n",
    "plt.title('harris corners plot for LEFT IMG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_coordsR = harris(imgRight,6)\n",
    "print(len(filtered_coordsR))\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(imgLeft)\n",
    "plt.plot([p[1] for p in filtered_coordsR],[p[0] for p in filtered_coordsR],\"*\")\n",
    "plt.title('harris corners plot for RIGHT IMG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formdescriptors(image,filtered_coords,wid=5):\n",
    "    desc = []\n",
    "    for coords in filtered_coords:\n",
    "        patch = image[coords[0]-wid:coords[0]+wid+1,\n",
    "        coords[1]-wid:coords[1]+wid+1].flatten()\n",
    "        desc.append(patch)\n",
    "    return desc\n",
    "\n",
    "def dist2(x, c):\n",
    "    \"\"\"\n",
    "    Calculates squared distance between two sets of points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy.ndarray\n",
    "        Data of shape `(ndata, dimx)`\n",
    "    c: numpy.ndarray\n",
    "        Centers of shape `(ncenters, dimc)`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n2: numpy.ndarray\n",
    "        Squared distances between each pair of data from x and c, of shape\n",
    "        `(ndata, ncenters)`\n",
    "    \"\"\"\n",
    "    assert x.shape[1] == c.shape[1], \\\n",
    "        'Data dimension does not match dimension of centers'\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)  # new shape will be `(1, ndata, dimx)`\n",
    "    c = np.expand_dims(c, axis=1)  # new shape will be `(ncenters, 1, dimc)`\n",
    "\n",
    "    # We will now use broadcasting to easily calculate pairwise distances\n",
    "    n2 = np.sum((x - c) ** 2, axis=-1)\n",
    "\n",
    "    return n2\n",
    "\n",
    "# according to Question 5: You can select all pairs whose descriptor distances \n",
    "# are below a specified threshold, or select the top few hundred descriptor pairs \n",
    "# with the smallest pairwise distances.\n",
    "\n",
    "def putMatch(desc1,desc2,threshold=0.5):\n",
    "    n = len(desc1[0])\n",
    "    \n",
    "    # Question 4: Compute distances between every descriptor in one image and every descriptor in the other image.\n",
    "    # will be using the provided dist2 function\n",
    "    d = -np.ones((len(desc1),len(desc2)))\n",
    "    \n",
    "    for i in range(len(desc1)):\n",
    "        for j in range(len(desc2)):\n",
    "            \n",
    "            d1 = (desc1[i] - np.mean(desc1[i])) / np.std(desc1[i])\n",
    "            \n",
    "            d2 = (desc2[j] - np.mean(desc2[j])) / np.std(desc2[j])\n",
    "            \n",
    "            # \"Alternatively, experiment with computing normalized correlation\"\n",
    "            #src: https://cseweb.ucsd.edu/classes/sp04/cse252b/notes/lec14/lec14.pdf\n",
    "            ncc_value = np.sum(d1 * d2) / (n-1)\n",
    "            if ncc_value > threshold:\n",
    "                d[i,j] = ncc_value\n",
    "                \n",
    "    ndx = np.argsort(-d)\n",
    "    matches = ndx[:,0]\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid = 5\n",
    "desL = formdescriptors(imgLeft,filtered_coordsL,wid)\n",
    "desR = formdescriptors(imgRight,filtered_coordsR,wid)\n",
    "matches = putMatch(desL,desR) # LATER CONVERTED TO HOMOGRAPHY POINTS w/ Ransac\n",
    "print(matches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # http://vision.cs.utexas.edu/378h-fall2015/slides/lecture14.pdf\n",
    "\n",
    "# 6. Run RANSAC to estimate a homography mapping one image onto the other. Report the number of inliers and the average\n",
    "# residual for the inliers (squared distance between the point coordinates in one image and the transformed coordinates of the\n",
    "# matching point in the other image). Also, display the locations of inlier matches in both images.\n",
    "\n",
    "# src: http://www.scipy.org/Cookbook/RANSAC -> ransac.py\n",
    "# Homography fitting calls for homogeneous least squares. The solution to the homogeneous least squares system AX=0 is\n",
    "# obtained from the SVD of A by the singular vector corresponding to the smallest singular value:\n",
    "# [U,S,V]=svd(A); X = V(:,end);\n",
    "\n",
    "class RansacModel(object):\n",
    "    def __init__(self,debug=False):\n",
    "        self.debug = debug\n",
    "    def fit(self, data):\n",
    "        \"\"\" Fit homography to four selected correspondences. \"\"\"\n",
    "        #########################################\n",
    "        # transpose \n",
    "        data = data.T\n",
    "        # from points\n",
    "        fp = data[:3,:4]\n",
    "        # target points\n",
    "        tp = data[:3,:4]\n",
    "\n",
    "        # fit homography and return\n",
    "        m = np.mean(fp[:2], axis=1)\n",
    "        maxstd = np.max(np.std(fp[:2], axis=1)) + 1e-9\n",
    "        C1 = np.diag([1/maxstd, 1/maxstd, 1])\n",
    "        C1[0][2] = -m[0]/maxstd\n",
    "        C1[1][2] = -m[1]/maxstd\n",
    "        fp = np.dot(C1,fp)\n",
    "\n",
    "        m = np.mean(tp[:2], axis=1)\n",
    "        maxstd = np.max(np.std(tp[:2], axis=1)) + 1e-9\n",
    "        C2 = np.diag([1/maxstd, 1/maxstd, 1])\n",
    "        C2[0][2] = -m[0]/maxstd\n",
    "        C2[1][2] = -m[1]/maxstd\n",
    "        tp = np.dot(C2,tp)\n",
    "\n",
    "        # create matrix for linear method, 2 rows for each correspondence pair\n",
    "        A = np.zeros((8,9))\n",
    "        for i in range(4): # using the corners\n",
    "            A[2*i] = [-fp[0][i],-fp[1][i],-1,0,0,0,tp[0][i]*fp[0][i],tp[0][i]*fp[1][i],tp[0][i]]\n",
    "            A[2*i+1] = [0,0,0,-fp[0][i],-fp[1][i],-1,tp[1][i]*fp[0][i],tp[1][i]*fp[1][i],tp[1][i]]\n",
    "\n",
    "        U,S,V = np.linalg.svd(A)\n",
    "        H = V[8].reshape((3,3))\n",
    "        # decondition\n",
    "        H = np.dot(np.linalg.inv(C2),np.dot(H,C1))\n",
    "        # normalize and return\n",
    "        return H / H[2,2]\n",
    "        \n",
    "    def get_error( self, data, H):\n",
    "        \"\"\" Apply homography to all correspondences,\n",
    "        return error for each transformed point. \"\"\"\n",
    "        data = data.T\n",
    "        fp = data[:3]\n",
    "        tp = data[3:]\n",
    "        # transform \n",
    "        fp_transformed = np.dot(H,fp)\n",
    "        # normalize the new coordinates\n",
    "        for i in range(3):\n",
    "            fp_transformed[i] /= fp_transformed[2]\n",
    "        \n",
    "        # return error per point\n",
    "        return np.sqrt( np.sum((tp-fp_transformed)**2,axis=0) )\n",
    "\n",
    "def H_from_ransac(fp,tp,model,maxiter=1000,match_threshold=10):\n",
    "    \"\"\" Robust estimation of homography H from point\n",
    "    correspondences using RANSAC (ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC).\n",
    "    input: fp,tp (3*n arrays) points in hom. coordinates. \"\"\"\n",
    "    \n",
    "    import ransac #ransac.py\n",
    "    \n",
    "    # group corresponding points\n",
    "    data = np.vstack((fp,tp))\n",
    "    # compute H and return\n",
    "    H,ransac_data = ransac.ransac(data.T,model,4,maxiter,match_threshold,10,return_all=True)\n",
    "    \n",
    "    return H, ransac_data[\"inliers\"]\n",
    "\n",
    "def make_homog(points):\n",
    "    \"\"\" Convert a set of points (dim*n array) to\n",
    "    homogeneous coordinates. \"\"\"\n",
    "    return np.vstack((points,np.ones((1,points.shape[1]))))\n",
    "\n",
    "ransac = RansacModel()\n",
    "\n",
    "fp = make_homog(imgLeft[:,:2].T)\n",
    "fp = fp.astype(int)\n",
    "tp = make_homog(imgRight[:,:2].T)\n",
    "tp = tp.astype(int)\n",
    "\n",
    "# https://tinyurl.com/yyn8wz2t\n",
    "H,inliers = H_from_ransac(fp,tp,ransac)\n",
    "\n",
    "print(\"# INLIERS\",len(inliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "# 7. Warp one image onto the other using the estimated transformation. To do this, you will need to learn about maketform and\n",
    "# imtransform functions.\n",
    "# 1. Load both images - convert to grayscale and double\n",
    "imgLeft = np.float32(np.array(Image.open('uttower_left.JPG').convert(\"L\")))\n",
    "imgRight = np.float32(np.array(Image.open('uttower_right.JPG').convert(\"L\"))) \n",
    "H = H_from_ransac(fp,tp,ransac)[0]\n",
    "# H = np.array([[1.4,0.05,-100],[0.05,1.5,-100],[0,0,1]]) #ransac H is not working ..\n",
    "\n",
    "transformImgLeft = ndimage.affine_transform(imgLeft,H[:2,:2],(H[0,2],H[1,2]))\n",
    "alpha = (transformImgLeft > 0)\n",
    "imgWarp = (1-alpha)*imgRight + alpha*transformImgLeft\n",
    "\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(imgWarpRansac)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"warped image w/ransac estimation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "# 7. Warp one image onto the other using the estimated transformation. To do this, you will need to learn about maketform and\n",
    "# imtransform functions.\n",
    "# 1. Load both images - convert to grayscale and double\n",
    "imgLeft = np.float32(np.array(Image.open('uttower_left.JPG').convert(\"L\")))\n",
    "imgRight = np.float32(np.array(Image.open('uttower_right.JPG').convert(\"L\"))) \n",
    "# H = H_from_ransac(fp,tp,ransac)[0]\n",
    "H = np.array([[1.4,0.05,-100],[0.05,1.5,-100],[0,0,1]]) #ransac H is not working ideally..\n",
    "\n",
    "transformImgLeft = ndimage.affine_transform(imgLeft,H[:2,:2],(H[0,2],H[1,2]))\n",
    "alpha = (transformImgLeft > 0)\n",
    "imgWarp = (1-alpha)*imgRight + alpha*transformImgLeft\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(imgWarp)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"warped image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create a new image big enough to hold the panorama and composite the two images into it. \n",
    "# You can composite by simply averaging the pixel values where the two images overlap. \n",
    "\n",
    "def panorama(H,fromim,toim,padding=2400,delta=2400):\n",
    "    # H from ransac will be used\n",
    "    # check if images are grayscale or color\n",
    "    is_color = len(fromim.shape) == 3\n",
    "    \n",
    "    # homography transformation for geometric_transform()\n",
    "    def transf(p):\n",
    "        p2 = np.dot(H,[p[0],p[1],1])\n",
    "        return (p2[0]/p2[2],p2[1]/p2[2])\n",
    "    \n",
    "    if H[1,2]<0: # fromim is to the right\n",
    "        # transform fromim\n",
    "        if is_color:\n",
    "            # pad the destination image with zeros to the right\n",
    "            toim_t = np.hstack((toim,np.zeros((toim.shape[0],padding,3))))\n",
    "            fromim_t = np.zeros((toim.shape[0],toim.shape[1]+padding,toim.shape[2]))\n",
    "            for col in range(3):\n",
    "                fromim_t[:,:,col] = ndimage.geometric_transform(fromim[:,:,col],\n",
    "                    transf,(toim.shape[0],toim.shape[1]+padding))\n",
    "        else:\n",
    "            # pad the destination image with zeros to the right\n",
    "            toim_t = np.hstack((toim,np.zeros((toim.shape[0],padding))))\n",
    "            fromim_t = ndimage.geometric_transform(fromim,transf,(toim.shape[0],toim.shape[1]+padding))\n",
    "    else:\n",
    "        # add translation to compensate for padding to the left\n",
    "        H_delta = np.array([[1,0,0],[0,1,-delta],[0,0,1]])\n",
    "        H = np.dot(H,H_delta)\n",
    "        # transform fromim\n",
    "        if is_color:\n",
    "            # pad the destination image with zeros to the left\n",
    "            toim_t = np.hstack((np.zeros((toim.shape[0],padding,3)),toim))\n",
    "            fromim_t = np.zeros((toim.shape[0],toim.shape[1]+padding,toim.shape[2]))\n",
    "            for col in range(3):\n",
    "                fromim_t[:,:,col] = ndimage.geometric_transform(fromim[:,:,col],transf,(toim.shape[0],toim.shape[1]+padding))\n",
    "        else:\n",
    "            # pad the destination image with zeros to the left\n",
    "            toim_t = np.hstack((np.zeros((toim.shape[0],padding)),toim))\n",
    "            fromim_t = ndimage.geometric_transform(fromim,transf,(toim.shape[0],toim.shape[1]+padding))\n",
    "            \n",
    "    # blend and return (left image above right =-> then average the overlapping pixels)\n",
    "    if is_color:\n",
    "        # all non black pixels\n",
    "        alpha = ((fromim_t[:,:,0] * fromim_t[:,:,1] * fromim_t[:,:,2] ) > 0)\n",
    "        for col in range(3):\n",
    "            toim_t[:,:,col] = fromim_t[:,:,col]*alpha + toim_t[:,:,col]*(1-alpha)\n",
    "    else:\n",
    "        alpha = (fromim_t < 0)\n",
    "        toim_t = fromim_t*alpha + toim_t*(1-alpha)\n",
    "        \n",
    "    return toim_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load both images - convert to grayscale and double\n",
    "imgLeft = np.float32(np.array(Image.open('uttower_left.JPG').convert(\"L\")))\n",
    "imgRight = np.float32(np.array(Image.open('uttower_right.JPG').convert(\"L\"))) \n",
    "\n",
    "H = H_from_ransac(fp,tp,ransac)[0]\n",
    "# H = np.array([[1.4,0.05,-100],[0.05,1.5,-100],[0,0,1]]) #ransac H is not working ideally..\n",
    "\n",
    "imgPanoGray = panorama(H,imgLeft,imgRight,10,500)\n",
    "\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(imgPanoGray)\n",
    "plt.title(\"pano in grayscale b/w left and right img\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgLeftC = np.float32(np.array(Image.open('uttower_left.JPG').convert(\"RGB\")))\n",
    "imgRightC = np.float32(np.array(Image.open('uttower_right.JPG').convert(\"RGB\"))) \n",
    "\n",
    "# H = H_from_ransac(fp,tp,ransac)[0]\n",
    "H = np.array([[1.4,0.05,-100],[0.05,1.5,-100],[0,0,1]]) #ransac H is not working ideally..\n",
    "imgPanoColor = panorama(H,imgLeftC,imgRightC,10,10)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(imgPanoColor)\n",
    "plt.title(\"pano in color b/w left and right img\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
